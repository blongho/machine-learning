{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/blongho/machine-learning/blob/master/HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vNf-yPJOx75"
      },
      "source": [
        "# Homework 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKdfRsPZOx7-"
      },
      "source": [
        "This homework mainly evaluates if you are familar with NumPy to create machine learning related functions. Thus, all your functions here should be only made using NumPy, not any other libraries like pandas, scikit-learn, or scipy. We will run a complete machine learning process from preprocessing to model performance testing by using the functions we will develop.\n",
        "\n",
        "### This assignment is made to practice the features of NumPy. Therefore, the use of a for loop is strictly prohibited. All problems can be solved without explicit loops. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9BPzS0g9Ox7-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the lab session, we try to draw a regression line on the full dataset. Here in this homework, we will continue to use the same dataset we have used in the first lab, as well as the code we have made. However, this time we would like to create a model and even test it - by dividing the dataset into a training set and a test set. We will practice applying each function one after the other in the correct order. \n",
        "\n",
        "To practice NumPy efficiently, unlike the lab, we will only use the values of the dataset, ignoring Pandas properties such as column names.\n",
        "\n",
        "- Run the block below to load the dataset (**X** and **y**)."
      ],
      "metadata": {
        "id": "svj3G7hj4ZxY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "\n",
        "california_housing = fetch_california_housing(as_frame=False)\n",
        "\n",
        "X = california_housing.data\n",
        "y = california_housing.target"
      ],
      "metadata": {
        "id": "2HAUc00Wmu0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we are ready to use both features and labels. To handle it correctly, you need to be familiar with its axis concept as it no longer has indices and columns that you can check by printing the variable."
      ],
      "metadata": {
        "id": "-txQY1eUoWeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4KbMNxMm9Oi",
        "outputId": "ec0aaaf7-5dea-42b9-a0c0-a3009d9b9b87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   8.3252    ,   41.        ,    6.98412698, ...,    2.55555556,\n",
              "          37.88      , -122.23      ],\n",
              "       [   8.3014    ,   21.        ,    6.23813708, ...,    2.10984183,\n",
              "          37.86      , -122.22      ],\n",
              "       [   7.2574    ,   52.        ,    8.28813559, ...,    2.80225989,\n",
              "          37.85      , -122.24      ],\n",
              "       ...,\n",
              "       [   1.7       ,   17.        ,    5.20554273, ...,    2.3256351 ,\n",
              "          39.43      , -121.22      ],\n",
              "       [   1.8672    ,   18.        ,    5.32951289, ...,    2.12320917,\n",
              "          39.43      , -121.32      ],\n",
              "       [   2.3886    ,   16.        ,    5.25471698, ...,    2.61698113,\n",
              "          39.37      , -121.24      ]])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rTO_NYMNHlg",
        "outputId": "22fdd915-b069-41b0-c023-50fa9bbb68ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbj_IpkHOx8A"
      },
      "source": [
        "### 1. Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EE0ALwTyOx8A"
      },
      "source": [
        "The first task is to open the dataset and preprocess it into the form that the model can understand. It involves imputation, train_test_split, standardization, and normalization. Some functions are already covered by the first lab, so if you finished the lab before, you can freely bring your code here to finish your homework.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we would like to apply both standardization and normalization. You can re-use your lab functions here if you have finished your lab tasks.\n",
        "\n",
        "\n",
        "- Standardization: Make features have the same standard deviaton and mean.\n",
        "\n",
        "- Normalization: Make the range of value normalized into [0, 1]."
      ],
      "metadata": {
        "id": "t2uFZSUuoh9t"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQRVVievOx8A"
      },
      "outputs": [],
      "source": [
        "def standardize(data):\n",
        "  \"\"\"\n",
        "  Input: NumPy ndarray\n",
        "  Output: NumPy ndarray with column mean == 0 and std == 1\n",
        "  \"\"\"\n",
        "  df = (data-data.mean(axis=0))/data.std(axis=0)\n",
        "  return df\n",
        "\n",
        "def normalize(data):\n",
        "  \"\"\"\"\n",
        "  Input: NumPy ndarray\n",
        "  Output: NumPy ndarray with column min == 0 and max == 1\n",
        "  \"\"\"\n",
        "  df = (data - data.min(axis=0))/(data.max(axis=0) - data.min(axis=0))\n",
        "  return df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's apply both functions separately and create X_standardized and X_normalized."
      ],
      "metadata": {
        "id": "Cb4WgGQ0o_9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_standardized = standardize(X)\n",
        "X_normalized = normalize(X)"
      ],
      "metadata": {
        "id": "2qf7fOZG54MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We may also need to check if those functions are correctly made. Create a function to check the dataset's min, max, mean, std of each feature. You can re-use your lab function (**describe**) but this time you are not allowed to use pandas dataframe. There is no expected format for this function if you are successfully able to plot four statistics (min, max, mean, std)."
      ],
      "metadata": {
        "id": "So46vKNl53KL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def describe(data: np.array):\n",
        "  \"\"\"\n",
        "  Describe four statistics of the dataset.\n",
        "  \n",
        "  Input: NumPy ndarray\n",
        "  Output: vertical min, max, mean, standard deviation\n",
        "  \"\"\"\n",
        "  min_values = data.min(axis=0)\n",
        "  #np.min(data, axis=0)\n",
        "  max_values = data.max(axis=0)\n",
        "  avg_values = data.mean(axis=0)\n",
        "  std_values = data.std(axis=0)\n",
        " \n",
        "  #print(min_values, max_values, avg_values, std_values)\n",
        "  print(\"Min\\t\", end=\"\")\n",
        "\n",
        "  for val in min_values:\n",
        "    print(f\"{round(val, 4):>8}\", end=\"\\t\")\n",
        "\n",
        "  print(\"\\nMax\\t\", end=\"\")\n",
        "  for val in max_values:\n",
        "    print(f\"{round(val, 4):>8}\", end=\"\\t\")\n",
        "  \n",
        "  print(\"\\nMean\\t\", end=\"\")\n",
        "  for val in avg_values:\n",
        "    print(f\"{round(val, 4):>8}\", end=\"\\t\")\n",
        "\n",
        "  print(\"\\nStd\\t\", end=\"\")\n",
        "  for val in std_values:\n",
        "    print(f\"{round(val, 4):>8}\", end=\"\\t\")\n",
        "  return None"
      ],
      "metadata": {
        "id": "l9BqVsG36Tsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using this function, let's check if your **standardize** and **normalize** functions are correctly working. Your output should be the same as the one below."
      ],
      "metadata": {
        "id": "FZEPPjpJ6W3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "describe(X_standardized)"
      ],
      "metadata": {
        "id": "1NY6wtki6c84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a7ecdd-1e78-49cf-abea-e6bcbe94f13d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min\t -1.7743\t -2.1962\t -1.8523\t -1.6108\t -1.2561\t  -0.229\t -1.4476\t  -2.386\t\n",
            "Max\t  5.8583\t  1.8562\t 55.1632\t 69.5717\t 30.2503\t119.4191\t  2.9581\t  2.6253\t\n",
            "Mean\t     0.0\t     0.0\t     0.0\t    -0.0\t    -0.0\t     0.0\t    -0.0\t    -0.0\t\n",
            "Std\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "describe(X_normalized)"
      ],
      "metadata": {
        "id": "G7-p5vdl3H4F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41e5666e-ebbd-44dc-de10-f50e9ed1b51b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min\t     0.0\t     0.0\t     0.0\t     0.0\t     0.0\t     0.0\t     0.0\t     0.0\t\n",
            "Max\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t\n",
            "Mean\t  0.2325\t   0.542\t  0.0325\t  0.0226\t  0.0399\t  0.0019\t  0.3286\t  0.4761\t\n",
            "Std\t   0.131\t  0.2468\t  0.0175\t   0.014\t  0.0317\t  0.0084\t   0.227\t  0.1996\t"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, this is not a complete setting we would like to have, as we want to train the model and also test it. That means we need to divide the dataset into two parts: {Training set, Test set} and only use the training set to train the model. We also need to create the function for it."
      ],
      "metadata": {
        "id": "mj47zZ264Az0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split(X, y, test_ratio = 0.3):\n",
        "  # simulation\n",
        "  # cross-val\n",
        "  \n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - X: features\n",
        "    - y: labels\n",
        "    - test_ratio: ratio of the test set\n",
        "    \n",
        "  Output:\n",
        "    - X_train: separated training instances\n",
        "    - X_test: separated test instances\n",
        "    - y_train: separated training labels\n",
        "    - y_test: separated test labels\n",
        "  \n",
        "  1. Randomly shuffled indices of the size of the data instances\n",
        "  2. Divide the indices into two parts with the ratio of [1-test ratio:test ratio]\n",
        "  3. Select training instances and labels with the first set of indices and test instances and labels with the second set of indices\n",
        "  4. Return the training set and the test set\n",
        "  \"\"\"\n",
        "  shuffled_index_list = np.random.permutation(len(X))\n",
        "  number_of_test_set = int(len(X)*test_ratio)\n",
        "  test_set_indices = shuffled_index_list[:number_of_test_set]\n",
        "  training_set_indices = shuffled_index_list[number_of_test_set:]\n",
        " \n",
        "  X_train = X[training_set_indices]\n",
        "  X_test = X[test_set_indices]\n",
        "  y_train =y[training_set_indices]\n",
        "  y_test = y[test_set_indices]\n",
        "  \n",
        "  return X_train, X_test, y_train, y_test"
      ],
      "metadata": {
        "id": "ORFET61FbZVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split your dataset into training and test sets with `test ratio = 0.3`."
      ],
      "metadata": {
        "id": "twOo6_yniUGO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, 0.3)"
      ],
      "metadata": {
        "id": "f-iSb7IoijO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After applying your train_test_split function, you can check the shape of each subset. The training set should have 14,448 rows while the test set might have 6,192 records. Uncommend the below line."
      ],
      "metadata": {
        "id": "d9PK6RGbkK7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "bk_pMMo-iquK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3617541-5cde-49c3-fb42-a4fd7326b48d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((14448, 8), (6192, 8), (14448,), (6192,))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You may remember, when you apply standardization or normalization on both training and test sets, you should not use any statistics from the test set. This means that you should use mean and standard deviation (or max and min values) of the training set and use those statistics to avoid cheating and make a valid model. \n",
        "\n",
        "- Create two functions (**apply_standardization**, **apply_normalization**) that uses training set's statistics and apply standardization or normalization to both sets."
      ],
      "metadata": {
        "id": "7T8JBhsTj00O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_standardization(X_train, X_test):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - X_train: training instances\n",
        "    - X_test: test instances\n",
        "\n",
        "  Output:\n",
        "    - X_train_standardized\n",
        "    - X_test_standardized\n",
        "\n",
        "  Use training set's mean and standard deviation to standardize both training and test sets\n",
        "  \"\"\"\n",
        "  x_train = (X_train-X_train.mean(axis=0))/X_train.std(axis=0)\n",
        "  x_test = (X_test - X_train.mean(axis=0))/X_train.std(axis=0)\n",
        "  return x_train, x_test"
      ],
      "metadata": {
        "id": "XLs3P181kYHA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_normalization(X_train, X_test):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - X_train\n",
        "    - X_test\n",
        "\n",
        "  Output:\n",
        "    - X_train_standardized\n",
        "    - X_test_standardized\n",
        "  \"\"\"\n",
        "  x_train = (X_train - X_train.min(axis=0))/(X_train.max(axis=0) - X_train.min(axis=0))\n",
        "  y_test = (X_test - X_train.min(axis=0))/(X_test.max(axis=0) - X_train.min(axis=0))\n",
        "  return x_train, y_test"
      ],
      "metadata": {
        "id": "sOx7Kd221jRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Apply two functions (**apply_standardization**, **apply_normalization**) to created standardized and normalized datasets."
      ],
      "metadata": {
        "id": "ujWQ84ZFCa10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_standardized, X_test_standardized = apply_standardization(X_train, X_test)\n",
        "X_train_normalized, X_test_normalized = apply_normalization(X_train, X_test)"
      ],
      "metadata": {
        "id": "Cw8tjyoCtnqI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check the statistics using describe method. Test set should NOT have zero mean and standard deviation 1 or zero min and one max. Good test set however might show close value to zero or one."
      ],
      "metadata": {
        "id": "efxhH-DvCxBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "describe(X_train_standardized)"
      ],
      "metadata": {
        "id": "ch5zQTDDDugQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe35cf5-8e0a-49bf-f51c-2969c79afdad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min\t -1.7712\t -2.1863\t -1.9372\t -1.8625\t -1.2617\t -0.4498\t  -1.447\t -2.3707\t\n",
            "Max\t  5.8628\t  1.8526\t 57.7442\t  60.006\t   30.62\t117.1182\t   2.929\t  2.5074\t\n",
            "Mean\t    -0.0\t    -0.0\t     0.0\t    -0.0\t    -0.0\t     0.0\t     0.0\t    -0.0\t\n",
            "Std\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "describe(X_test_standardized)"
      ],
      "metadata": {
        "id": "8qyxhAClDx7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1170aa02-ae36-44c5-9736-19b51d876964"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min\t -1.7712\t -2.1071\t -1.8721\t -1.3786\t -1.2599\t -0.3719\t -1.4424\t  -2.311\t\n",
            "Max\t  5.8628\t  1.8526\t 53.7775\t  80.619\t 24.2614\t243.4391\t  2.8593\t  2.6269\t\n",
            "Mean\t  0.0116\t  0.0087\t  0.0056\t  0.0132\t  0.0313\t  0.0567\t -0.0306\t  0.0292\t\n",
            "Std\t  1.0006\t  0.9889\t  1.1485\t  1.4636\t  1.0388\t  3.3933\t  0.9771\t  0.9906\t"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "describe(X_train_normalized)"
      ],
      "metadata": {
        "id": "_tTsEozJ2_3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34c840b7-5f68-4755-8f88-da007e1d976b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min\t     0.0\t     0.0\t     0.0\t     0.0\t     0.0\t     0.0\t     0.0\t     0.0\t\n",
            "Max\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t\n",
            "Mean\t   0.232\t  0.5413\t  0.0325\t  0.0301\t  0.0396\t  0.0038\t  0.3307\t   0.486\t\n",
            "Std\t   0.131\t  0.2476\t  0.0168\t  0.0162\t  0.0314\t  0.0085\t  0.2285\t   0.205\t"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "describe(X_test_normalized)"
      ],
      "metadata": {
        "id": "bNplCpND3Byu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07c8f00b-1ef5-4ba2-e003-529f33bb077a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Min\t     0.0\t  0.0196\t  0.0012\t  0.0059\t  0.0001\t  0.0003\t  0.0011\t   0.012\t\n",
            "Max\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t     1.0\t\n",
            "Mean\t  0.2335\t  0.5435\t  0.0349\t  0.0227\t  0.0507\t  0.0021\t  0.3289\t  0.4802\t\n",
            "Std\t  0.1311\t  0.2448\t  0.0206\t  0.0177\t  0.0407\t  0.0139\t  0.2269\t  0.1982\t"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgG7BAsDOx8B"
      },
      "source": [
        "### 2. Linear regression"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to train and test our model. We will continue to use the linear regression that we have made in the lab using the normal equation. \n",
        "\n",
        "- Create the **solver** function that creates a linear regression line and return the coefficents. You can re-use the function from the first lab.\n",
        "- Here you should you all available features of the dataset.\n",
        "- You should add one column representing a bias to your feature matrix.\n",
        "\n",
        "The normal equation can be represented as follows:\n",
        "\n",
        "$\\theta = (\\textbf{X}^T \\cdot \\textbf{X})^{-1} \\cdot \\textbf{X}^T \\cdot \\textbf{y}$"
      ],
      "metadata": {
        "id": "aDLWBj56D6P6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EkjV6APOx8C"
      },
      "outputs": [],
      "source": [
        "def solver(X, y):\n",
        "  \"\"\"\n",
        "  Get the weight and bias of the linear regression line on the dataset X, using the labels y.\n",
        "\n",
        "  Input: \n",
        "   - X: features\n",
        "   - y: labels\n",
        "  Output:\n",
        "   - theta: weight and bias of the linear regression\n",
        "  \"\"\"\n",
        "  theta = np.linalg.inv(np.transpose(X)@X)@np.transpose(X)@y\n",
        "  return theta"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will only run this solver function on the training set (**X_train**, **y_train**) to create the model and evalute it by using the test set.\n",
        "\n",
        "- Run the **solve** function on **X_train** and **y_train** and save the result to **theta**."
      ],
      "metadata": {
        "id": "xWZhZW4rExeQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "theta = solver(X_train_standardized, y_train)"
      ],
      "metadata": {
        "id": "4_8ETLDgE_5p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a complete model trained on the training set. Then the next interesting thing is to evaluate if the model is good enough by using the test set. To do this, we need to create a predict function that can return the expected value. \n",
        "\n",
        "- Create the **predict** function which put each instance into the regression equation to predict the value. DO NOT USE ANY LOOP."
      ],
      "metadata": {
        "id": "dQDfYDDxF9o5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(X, theta):\n",
        "  \"\"\"\n",
        "  Input: \n",
        "   - X: data instances to predict\n",
        "   - theta: trained regression coefficients\n",
        "\n",
        "  Output:\n",
        "   - y_hat: predicted values (X @ weight) + bias\n",
        "  \"\"\"\n",
        "  y_hat =theta.dot(np.transpose(X)) + np.ones(len(X))\n",
        "  return y_hat"
      ],
      "metadata": {
        "id": "p-JxOI09ledN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This predict function should be able to return the predicted value of the housing price. Then now we might want to return the mean squared error of the whole model. There can be many different metrics but here we would like to measure rooted mean squared error. RMSE can be calculated as follows: "
      ],
      "metadata": {
        "id": "psp-L1wGRslu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "$RMSE = \\sqrt{\\frac{1}{n}\\sum_{t=1}^{n}(\\bar{y}_t - y_t)^2} $"
      ],
      "metadata": {
        "id": "ljB3uUqjWPbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create a function **rooted_mean_squared_error** that calculates the RMSE value."
      ],
      "metadata": {
        "id": "aMTnVQGPWfBv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laAN9bTMOx8C"
      },
      "outputs": [],
      "source": [
        "def rooted_mean_squared_error(X, y, theta):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - X_test: data instances to test\n",
        "    - y_test: true values of the corresponding data instances (X_test)\n",
        "    - theta: trained regression coefficients\n",
        "\n",
        "  Output:\n",
        "    - RMSE: RMSE score\n",
        "\n",
        "  Use predict function to calculate our predicted values.\n",
        "  \"\"\"\n",
        "\n",
        "  rmse = np.sqrt(np.sum(np.square(np.subtract(y,theta)))/len(X))\n",
        "  return rmse"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Run RMSE function to test our model created by our solver function. Use predict function to calculate our predicted values. Report the RMSE value."
      ],
      "metadata": {
        "id": "TReu0cnIWiz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Even though the RMSE is generally the preferred performance measure for\n",
        "regression tasks, in some contexts you may prefer to use another function. For\n",
        "example, suppose that there are many outlier districts. In that case, you may\n",
        "consider using the mean absolute error (MAE). It's direct translation of l1 and l2 norm. The higher the norm index, the more it focuses on large values and\n",
        "neglects small ones. This is why the RMSE is more sensitive to\n",
        "outliers than the MAE. But when outliers are exponentially rare (like\n",
        "in a bell-shaped curve), the RMSE performs very well and is\n",
        "generally preferred.\n",
        "\n",
        "MAE can be calculated as follows:\n",
        "\n",
        "$MAE = \\frac{1}{n}\\sum_{t=1}^{n}|\\bar{y}_t - y_t|$\n",
        "\n",
        "- Implement a function for MAE **mean_absolute_error**, which receives the same parameters *X*, *y*, and *theta*."
      ],
      "metadata": {
        "id": "52aH-ML6Seu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_absolute_error(X, y, theta):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - X_test: data instances to test\n",
        "    - y_test: true values of the corresponding data instances (X_test)\n",
        "    - theta: trained regression coefficients\n",
        "\n",
        "  Output:\n",
        "    - MAE: MAE score\n",
        "\n",
        "  Use predict function to calculate our predicted values.\n",
        "  \"\"\"\n",
        "  mae_score = (1/len(X)) * (np.sum(abs(np.subtract(y,theta))))\n",
        "  \n",
        "  return mae_score"
      ],
      "metadata": {
        "id": "uFEGAF7fqqeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train your regression model on the training set and evaluate your method with two different scores: RMSE and MAE. Print two scores here."
      ],
      "metadata": {
        "id": "PNC0hszHqyIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_score = rooted_mean_squared_error(X_test_standardized, y_test, theta) # CHANGE IT!\n",
        "mae_score = mean_absolute_error(X_test_standardized, y_test, theta) # CHANGE IT!"
      ],
      "metadata": {
        "id": "wm8gHjCSq64P",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "outputId": "54882d81-e13c-4ca4-8f1c-12926aaf4e00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-421f2d42bc78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrmse_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrooted_mean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_standardized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# CHANGE IT!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmae_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_standardized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# CHANGE IT!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-34796b7be161>\u001b[0m in \u001b[0;36mrooted_mean_squared_error\u001b[0;34m(X, y, theta)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \"\"\"\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mrmse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (6192,) (8,) "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmse_score, mae_score"
      ],
      "metadata": {
        "id": "LWaJtiItrmDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Linear regression with regularization"
      ],
      "metadata": {
        "id": "royxfFHjRjw2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You have learned the Ridge regression in the lecture. Fortunately, the Ridge regression also can be represented as a closed form solution with the normal equation. \n",
        "\n",
        "Your task here is to create a variant of your previous solver function supporting the Ridge regression. \n",
        "\n",
        "A closed form solution to Ridge can be represented as follows:\n",
        "\n",
        "$\\theta = (\\textbf{X}^T \\cdot \\textbf{X} + \\alpha\\textbf{I})^{-1} \\cdot \\textbf{X}^T \\cdot \\textbf{y}$\n",
        "\n",
        "where $\\textbf{I}$ is an $(n+1) \\times (n+1) $ identity matrix, since the feature matrix also includes the bias column.\n"
      ],
      "metadata": {
        "id": "wphcDNvvkwL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def solver_with_ridge(X, y, alpha):\n",
        "  \"\"\"\n",
        "  Get the weight and bias of the linear regression line on the dataset X, using the labels y.\n",
        "\n",
        "  Input: \n",
        "   - X: features\n",
        "   - y: labels\n",
        "  Output:\n",
        "   - theta: weight and bias of the ridge regression\n",
        "  \"\"\"\n",
        "  I = (X+1)*(X+1)\n",
        "  print(I)\n",
        "  thetha = np.linalg.inv(np.transpose(X)@X + alpha*I)@np.transpose(X)@y\n",
        "\n",
        "  return theta "
      ],
      "metadata": {
        "id": "jvYlCgotRlcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, compare the performances changing the $\\alpha$ value. Use the $\\alpha$ value from 0 to 30 in increments of 0.1. Use RMSE as a score metric. Save those 300 scores into the list `scores`. \n",
        "\n",
        "- To iterate different $\\alpha$s, you can use a loop for your convenience."
      ],
      "metadata": {
        "id": "G-LrDqWSmaGW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = np.arange(0,30,0.1)\n",
        "scores = []\n",
        "for alph in range(len(alpha)):\n",
        "  print(\"Current value of alpha is \",alpha)\n",
        "  scores.append(solver_with_ridge(X_standardized, y, alph))\n",
        "\n",
        "print(scores)"
      ],
      "metadata": {
        "id": "Vd9pJ8zUo_7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot the graph of different scores here. If you saved all scores in the list `scores`, you can simply run the block below. The resulting plot behaves in a different way based on your split training and test sets. Sometimes, the error just decreases or increases, but you can also see that the error decreases first, but after some point, it starts to increase. If you are interested, repeat many times to check different plots and you can even change the range from [0, 30] to something else. Uncomment the block below!"
      ],
      "metadata": {
        "id": "ILjT1k5FpLVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(np.arange(0, 30, 0.1), scores)\n",
        "plt.xlabel(\"alpha\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "--Ky0LHO0wqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Model validation"
      ],
      "metadata": {
        "id": "S3nHFnagh0nC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So far, you simply had one test set and one training set. Now the question is if those sets were enough to represent the dataset's distribution. To overcome this problem, various validation methods have been developed and used such as cross-validation or repeated holdout test. Here, you will develop one function that performs the repeated holdout test. The key strategy of it is to create a completely different training and test set pair for each iteration. You simply iterate holdout test that we performed many (k) times and return the average score.\n",
        "\n",
        "* You are allowed to use a for loop to iterate k different tests. However, you are not allowed to use the loop to create different indices to divide the dataset.\n",
        "* You can call the `train_test_split` function you have developed above if it helps your development process."
      ],
      "metadata": {
        "id": "p7MnVQ5Rryof"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def repeated_hold_out(X, y, k, test_ratio):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - X: features\n",
        "    - y: labels\n",
        "    - test_ratio: ratio of the test set\n",
        "  Output:\n",
        "    - score: the average of k different test scores\n",
        "  \n",
        "  1. Iterate k times to perform k validation processes.\n",
        "  2. For each iteration, split the dataset into the training and test sets with *random* indices.\n",
        "   - Note that each iteration should create different training and test sets.\n",
        "  3. Use *standardization* to fix the scale of the dataset, you should only use the training set's properties.\n",
        "  4. Fit your model with *solver* (without ridge) on the training set.\n",
        "  5. Save your *RMSE* score into the list *scores*\n",
        "  6. After all the iterations, return the average of *scores*.\n",
        "\n",
        "  \"\"\"\n",
        "  scores = []\n",
        "  for idx in range(k):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X,y,test_ratio)\n",
        "    x_train_st, x_test_st = apply_standardization(x_train, x_test)\n",
        "    theta = solver(x_train_st, y_train)\n",
        "    rmse_value = rooted_mean_squared_error(x_train, y_train, theta)\n",
        "    scores.append(rmse_value)\n",
        "  return np.mean(scores)"
      ],
      "metadata": {
        "id": "M7JEfZjGijfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run the line below to return your holdout score."
      ],
      "metadata": {
        "id": "Po5UX-gb2idF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "holdout_score = repeated_hold_out(X, y, k=5, test_ratio=0.2)\n",
        "holdout_score"
      ],
      "metadata": {
        "id": "QuMGeSGfLjAL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Put things together"
      ],
      "metadata": {
        "id": "D7mSIvYbRoQq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It's time to put everything you have done together here. We will create a function that manages whole process from receiving raw datasets to returning performance metrics, by modifying the repeated holdout function. This will help you manage your process clearly since it must contain all the functions you use for your dataset (Later we will replace it with scikit-learn's pipeline technique for the same purpose) - By having these management functions, you can switch off some of the techniques or add more techniques in the middle without any problem.\n",
        "\n",
        "* Complete three functions (preprocess, fit, run) following the instruction."
      ],
      "metadata": {
        "id": "DWjft22LHEJm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def repeated_hold_out_2(X, y, k = 5, test_ratio = 0.2, norm_method = \"standardization\", eval_method = \"RMSE\", alpha = 0):\n",
        "  \"\"\"\n",
        "  Input:\n",
        "    - X: features\n",
        "    - y: labels\n",
        "    - test_ratio: ratio of the test set\n",
        "  Output:\n",
        "    - score: the average of k different test scores\n",
        "  \n",
        "  1. Iterate k times to perform k validation processes.\n",
        "  2. For each iteration, split the dataset into the training and test sets with *random* indices.\n",
        "   - Note that each iteration should create different training and test sets.\n",
        "  3. Check the parameter *norm_method*\n",
        "    - if norm_method == standardization:\n",
        "      - Use *standardization* to fix the scale of the dataset, you should only use the training set's properties.\n",
        "    - if norm_method == normalization:\n",
        "      - Use *normalization* to fix the scale of the dataset, you should only use the training set's properties.\n",
        "  4. Fit your model with *solver_with_ridge\" on the training set. Use alpha from the parameter.\n",
        "  5. Check the parameter \"eval_method\"\n",
        "    - if eval_method == \"RMSE\"\n",
        "      - Save your *RMSE* score into the list *scores*\n",
        "    - if eval_method == \"MAE\"\n",
        "      - Save your *MAE* score into the list *scores*\n",
        "\n",
        "  6. After all the iterations, return the average of *scores*.\n",
        "\n",
        "  \"\"\"\n",
        "  scores = []\n",
        "  for idx in range(k):\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X,y,test_ratio)\n",
        "    if norm_method == \"standardization\":\n",
        "      x_train_st, y_train_st = apply_standardization(x_train, x_test)\n",
        "    if norm_method == \"normalization\":\n",
        "      x_train_st, y_train_st = apply_normalization(x_train, x_test)\n",
        "    weight = solver_with_ridge(x_train_st, y_train_st, alpha)\n",
        "    if eval_method == \"RMSE\":\n",
        "      score = rooted_mean_squared_error(x_train_st, y_train_st, weight)\n",
        "    if eval_method == \"MAE\":\n",
        "      score = mean_absolute_error(x_train_st, y_train_st, weight)\n",
        "    scores.append(score)\n",
        "\n",
        "  return np.mean(scores)"
      ],
      "metadata": {
        "id": "6CU_kV0DRpYg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now you are ready to run various tasks by using this single function. Will the best model the same under RMSE or MAE? Will different k or test ratio result in different best model? You can do many different trials to find a good model.\n",
        "\n",
        "- (Optional) Change a normalization method, an alpha value to find out the best classifier under either RMSE or MAE score. This task is completely optional and will not affect your homework grade."
      ],
      "metadata": {
        "id": "P7GKrthoLOlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = None"
      ],
      "metadata": {
        "id": "bkCeCDoPLNGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# END"
      ],
      "metadata": {
        "id": "cWugHCgB2Cpq"
      }
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "HW1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}